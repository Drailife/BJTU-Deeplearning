{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a68242",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基本信息\n",
    "1. 实验名称：网络优化实验\n",
    "2. 姓名：戴斌斌\n",
    "3. 学号：20281239\n",
    "4. 日期：2022/11/14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11247ddf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc61ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 一、任务1-在多分类任务实验中手动实现dropout\n",
    "\n",
    "## 1.1 任务内容\n",
    "\n",
    "1. 任务具体要求  \n",
    "在多分类任务实验中分别手动实现dropout  \n",
    "探究不同丢弃率对实验结果的影响（可用loss曲线进行展示）\n",
    "2. 任务目的  \n",
    "探究不同丢弃率对实验结果的影响\n",
    "3. 任务算法或原理介绍    \n",
    "Dropout 原理   \n",
    "![](https://drailife.oss-cn-beijing.aliyuncs.com/img/202211112255396.png)\n",
    "4. 任务所用数据集   \n",
    "   MNIST手写体数据集:  \n",
    "     + 该数据集包含60,000个用于训练的图像样本和10,000个用于测试的图像样本。  \n",
    "     + 图像是固定大小(28x28像素)，其值为0到1。为每个图像都被平展并转换为784  \n",
    "        \n",
    "## 1.2 任务思路及代码  \n",
    "\n",
    "1. 构建数据集\n",
    "2. 构建前馈神经网络，损失函数，优化函数\n",
    "3. 手动实现dropout\n",
    "3. 使用网络预测结果，得到损失值  \n",
    "4. 进行反向传播，和梯度更新  \n",
    "5. 对loss、acc等指标进行分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45e34d-3d64-4a87-90b7-a154645d41ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.0数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ab1954-65ee-4629-8be4-606bb4a7bbc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的device为cuda\n",
      "多分类数据集 样本总数量70000,训练样本数量60000,测试样本数量10000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy, binary_cross_entropy\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import transforms\n",
    "from sklearn import  metrics\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 如果有gpu则在gpu上计算 加快计算速度\n",
    "print(f'当前使用的device为{device}')\n",
    "# 数据集定义\n",
    "# 定义多分类数据集 - train_dataloader - test_dataloader\n",
    "batch_size = 128\n",
    "# Build the training and testing dataset\n",
    "traindataset = torchvision.datasets.FashionMNIST(root='E:\\\\DataSet\\\\FashionMNIST\\\\Train',\n",
    "                                                  train=True,\n",
    "                                                  download=True,\n",
    "                                                  transform=transforms.ToTensor())\n",
    "testdataset = torchvision.datasets.FashionMNIST(root='E:\\\\DataSet\\\\FashionMNIST\\\\Test',\n",
    "                                                 train=False,\n",
    "                                                 download=True,\n",
    "                                                 transform=transforms.ToTensor())\n",
    "traindataloader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "testdataloader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size, shuffle=False)\n",
    "# 绘制图像的代码\n",
    "def picture(name, trainl, testl, type='Loss'):\n",
    "    plt.rcParams[\"font.sans-serif\"]=[\"SimHei\"] #设置字体\n",
    "    plt.rcParams[\"axes.unicode_minus\"]=False #该语句解决图像中的“-”负号的乱码问题\n",
    "    plt.title(name) # 命名\n",
    "    plt.plot(trainl, c='g', label='Train '+ type)\n",
    "    plt.plot(testl, c='r', label='Test '+type)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "print(f'多分类数据集 样本总数量{len(traindataset) + len(testdataset)},训练样本数量{len(traindataset)},测试样本数量{len(testdataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c4b665-1c50-4a34-a557-36db17664b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自己的前馈神经网络\n",
    "class MyNet():\n",
    "    def __init__(self,dropout=0):\n",
    "        # 设置隐藏层和输出层的节点数\n",
    "        self.dropout = dropout\n",
    "        self.is_train = None\n",
    "        num_inputs, num_hiddens, num_outputs = 28 * 28, 256, 10  # 十分类问题\n",
    "        w_1 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_inputs)), dtype=torch.float32,\n",
    "                           requires_grad=True)\n",
    "        b_1 = torch.zeros(num_hiddens, dtype=torch.float32, requires_grad=True)\n",
    "        w_2 = torch.tensor(np.random.normal(0, 0.01, (num_outputs, num_hiddens)), dtype=torch.float32,\n",
    "                           requires_grad=True)\n",
    "        b_2 = torch.zeros(num_outputs, dtype=torch.float32, requires_grad=True)\n",
    "        self.params = [w_1, b_1, w_2, b_2]\n",
    "\n",
    "        # 定义模型结构\n",
    "        self.input_layer = lambda x: x.view(x.shape[0], -1)\n",
    "        self.hidden_layer = lambda x: self.my_relu(torch.matmul(x, w_1.t()) + b_1)\n",
    "        self.output_layer = lambda x: torch.matmul(x, w_2.t()) + b_2\n",
    "    \n",
    "    def my_relu(self, x):\n",
    "        return torch.max(input=x, other=torch.tensor(0.0))\n",
    "    # 以下两个函数分别在训练和测试前调用，选择是否需要dropout\n",
    "    def train(self):\n",
    "        self.is_train = True\n",
    "    def test(self):\n",
    "        self.is_train = False\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        if self.is_train:\n",
    "            x = dropout_layer(x,dropout=self.dropout)\n",
    "        x = self.hidden_layer(x)\n",
    "        if self.is_train:\n",
    "            x = dropout_layer(x,dropout=self.dropout)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "定义dropout层\n",
    "x: 输入数据\n",
    "dropout: 随机丢弃的概率\n",
    "\"\"\"\n",
    "def dropout_layer(x, dropout):\n",
    "    assert 0 <= dropout <= 1 #dropout值必须在0-1之间\n",
    "    # dropout==1，所有元素都被丢弃。\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(x)\n",
    "        # 在本情况中，所有元素都被保留。\n",
    "    if dropout == 0:\n",
    "        return x\n",
    "    mask = (torch.rand(x.shape) > dropout).float() #rand()返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数\n",
    "    return mask * x / (1.0 - dropout)\n",
    "\n",
    "# 默认的优化函数为手写的mySGD\n",
    "def mySGD(params, lr, batchsize):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batchsize\n",
    "\"\"\"\n",
    "定义训练函数\n",
    "model:定义的模型 默认为MyNet(0) 即无dropout的初始网络\n",
    "epochs:训练总轮数 默认为40\n",
    "criterion:定义的损失函数，默认为cross_entropy\n",
    "lr :学习率 默认为0.01\n",
    "optimizer:定义的优化函数，默认为自己定义的mySGD函数\n",
    "\"\"\"\n",
    "def train_and_test(model=MyNet(),epochs=40,criterion = cross_entropy,lr=0.01,optimizer=mySGD):\n",
    "    train_all_loss = []  # 记录训练集上得loss变化\n",
    "    test_all_loss = []  # 记录测试集上的loss变化\n",
    "    train_ACC, test_ACC = [], [] # 记录正确的个数\n",
    "    begintime = time.time()\n",
    "    model.train() #表明当前处于训练状态，允许使用dropout\n",
    "    for epoch in range(epochs):\n",
    "        train_l,train_acc_num = 0, 0\n",
    "        for data, labels in traindataloader:\n",
    "            pred = model.forward(data)\n",
    "            train_each_loss = criterion(pred, labels)  # 计算每次的损失值\n",
    "            train_l += train_each_loss.item()\n",
    "            train_each_loss.backward()  # 反向传播\n",
    "            optimizer(model.params, lr, 128)  # 使用小批量随机梯度下降迭代模型参数\n",
    "            # 梯度清零\n",
    "            train_acc_num += (pred.argmax(dim=1)==labels).sum().item()\n",
    "            for param in model.params:\n",
    "                param.grad.data.zero_()\n",
    "            # print(train_each_loss)\n",
    "        train_all_loss.append(train_l)  # 添加损失值到列表中\n",
    "        train_ACC.append(train_acc_num / len(traindataset)) # 添加准确率到列表中\n",
    "        model.test() # 表明当前处于测试状态，无需使用dropout\n",
    "        with torch.no_grad():\n",
    "            is_train = False  # 表明当前为测试阶段，不需要dropout参与\n",
    "            test_l, test_acc_num = 0, 0\n",
    "            for data, labels in testdataloader:\n",
    "                pred = model.forward(data)\n",
    "                test_each_loss = criterion(pred, labels)\n",
    "                test_l += test_each_loss.item()\n",
    "                test_acc_num += (pred.argmax(dim=1)==labels).sum().item()\n",
    "            test_all_loss.append(test_l)\n",
    "            test_ACC.append(test_acc_num / len(testdataset))   # # 添加准确率到列表中\n",
    "        if epoch == 0 or (epoch + 1) % 4 == 0:\n",
    "            print('epoch: %d | train loss:%.5f | test loss:%.5f | train acc: %.2f | test acc: %.2f'\n",
    "                  % (epoch + 1, train_l, test_l, train_ACC[-1],test_ACC[-1]))\n",
    "    endtime = time.time()\n",
    "    print(\"手动实现dropout = 0.2 %d轮 总用时: %.3f\" % (epochs, endtime - begintime))\n",
    "    return train_all_loss,test_all_loss,train_ACC,test_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aac301-fe38-4140-a9db-1546079567e2",
   "metadata": {},
   "source": [
    "### 1.2.1 手动实验-设置dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b3f27-e503-4902-98b0-a344330384a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    设置dropout = 0  dropout = 0  epoch = 40  lr = 0.10  optimizer = mySGD\n",
    "\"\"\"\n",
    "model_11 = MyNet(dropout=0)\n",
    "train_and_test(model=model_11,epochs=40,lr=0.01,optimizer=mySGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e681e5-2b89-4083-85a8-71249ae56686",
   "metadata": {},
   "source": [
    "### 1.2.2 手动实验-设置dropout = 0.3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c5db4-7faa-425f-b8aa-8fd5898aa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    设置dropout = 0.3  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\"\"\"\n",
    "model_12 = MyNet(dropout=0.3)\n",
    "train_and_test(model=model_12,epochs=40,lr=0.01,optimizer=mySGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fb582-89d6-44b4-846d-f5ae00671374",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.3 手动实验-设置dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe88cda-744d-4de9-a3ef-e6b0c04d35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    设置dropout = 0.6  dropout = 0.6  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\"\"\"\n",
    "model_13 = MyNet(dropout=0.6)\n",
    "train_and_test(model=model_13,epochs=40,lr=0.01,optimizer=mySGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6f660-aa81-4457-b4d5-b9bd611c207f",
   "metadata": {},
   "source": [
    "### 1.2.4 手动实验-设置dropout = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe8766-4579-4d2e-a32c-b6d51749708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    设置dropout = 0.9  dropout = 0.9  epoch = 40  lr = 0.05  optimizer = mySGD\n",
    "\"\"\"\n",
    "model_14 = MyNet(dropout=0.9)\n",
    "train_and_test(model=model_14,epochs=40,lr=0.05,optimizer=mySGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbf009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3 实验结果分析  \n",
    "将上述前馈网络回归任务每一轮得训练和测试得损失值绘制成图表，如下图："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c151c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "将上述的二分类和多分类的正确率绘制成表格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca0561",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5e7c2-1a1e-45e7-8b06-31f5d0b51691",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.1 torch.nn实现前馈神经网络-回归任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b273f-2550-4aa0-8cab-fbec255294fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.2 torch.nn实现前馈神经网络-二分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1200b9b-da27-46e7-a8c7-474afb88a855",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.3 torch.nn实现前馈神经网络-多分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8191c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 2.3 实验结果分析  \n",
    "将上述前馈网络回归任务每一轮得训练和测试得损失值绘制成图表，如下图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e17d1d-e488-4247-ab0c-f0230d7cd2cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "picture('前馈网络-回归-loss',train_all_loss21,test_all_loss21)\n",
    "plt.subplot(132)\n",
    "picture('前馈网络-二分类-loss',train_all_loss22,test_all_loss22)\n",
    "plt.subplot(133)\n",
    "picture('前馈网络-多分类-loss',train_all_loss23,test_all_loss23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eca5d-c3a7-4ebb-b67d-b7188f6dd007",
   "metadata": {},
   "source": [
    "将上述前馈网络回归任务每一轮得训练和测试得准确率值绘制成图表，如下图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ddf37-b230-4965-981b-400a176f73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(121)\n",
    "picture('前馈网络-二分类-ACC',train_ACC22,test_ACC22,type='ACC')\n",
    "plt.subplot(122)\n",
    "picture('前馈网络-多分类-ACC',train_ACC23,test_ACC23,type='ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa0e2b-3d98-4231-a9dd-a62642254403",
   "metadata": {},
   "source": [
    "torch.nn实现的前馈网络在不同的数据集上表现出不同的效果，在回归问题中，损失函数下降速度极快，在前几轮就充分训练模型，并取得较好的效果。  \n",
    "在二分类中，loss值稳步下降，准确率逐步提升。  \n",
    "在多分类中，数据的规模较大，loss值在前6轮中下降较快，准确率提升较大，在后续的训练中，loss值相比前几轮下降较慢，准确率提升速度也不及前几轮。同时由于训练轮数的不足，模型并未没被完全训练好，可以通过增大epochs和lr来解决这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f592e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabe468",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# A1 实验心得\n",
    "\n",
    "学会手动构建前馈神经网络和利用torch.nn构建前馈神经网络解决回归、二分类、和多分类问题\n",
    "1. 实验中发现学习率的设置至关重要，如果学习率过大则会导致准确率下降的趋势，若学习率过小会导致模型需要更多时间收敛\n",
    "2. 实验过程中发现出现过拟合现象，通过修改相关参数得以纠正\n",
    "3. 学会程序模块话的编写，避免重复编写代码\n",
    "4. 对激活函数的选取有了更加清晰的认识\n",
    "5. 隐藏层的个数和隐藏层的神经元个数对模型有着很大的影响。\n",
    "\n",
    "# A2 参考文献  \n",
    "参考课程PPT"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
