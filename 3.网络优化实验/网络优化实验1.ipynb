{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a68242",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基本信息\n",
    "1. 实验名称：网络优化实验\n",
    "2. 姓名：无\n",
    "3. 学号：无\n",
    "4. 日期：1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11247ddf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc61ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 一、在多分类任务中分别手动实现和用torch.nn实现dropout\n",
    "\n",
    "## 1.1 任务内容\n",
    "\n",
    "1. 任务具体要求  \n",
    "在多分类任务实验中分别手动和利用torch.nn实现dropout  \n",
    "探究不同丢弃率对实验结果的影响（可用loss曲线进行展示）\n",
    "2. 任务目的  \n",
    "探究不同丢弃率对实验结果的影响\n",
    "3. 任务算法或原理介绍    \n",
    "Dropout 原理   \n",
    "![]\n",
    "4. 任务所用数据集   \n",
    "   MNIST手写体数据集:  \n",
    "     + 该数据集包含60,000个用于训练的图像样本和10,000个用于测试的图像样本。  \n",
    "     + 图像是固定大小(28x28像素)，其值为0到1。为每个图像都被平展并转换为784  \n",
    "        \n",
    "## 1.2 任务思路及代码  \n",
    "\n",
    "1. 构建数据集\n",
    "2. 构建前馈神经网络，损失函数，优化函数\n",
    "3. 手动实现dropout\n",
    "4. 进行反向传播，和梯度更新  \n",
    "5. 使用网络预测结果，得到损失值  \n",
    "6. 对loss、acc等指标进行分析，探究不同丢弃率对实验结果的影响  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45e34d-3d64-4a87-90b7-a154645d41ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### 1.2.0数据集定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ab1954-65ee-4629-8be4-606bb4a7bbc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用的device为cuda\n",
      "多分类数据集 样本总数量70000,训练样本数量60000,测试样本数量10000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy, binary_cross_entropy\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import transforms\n",
    "from sklearn import  metrics\n",
    " # 如果有gpu则在gpu上计算 加快计算速度\n",
    "print(f'当前使用的device为{device}')\n",
    "# 数据集定义\n",
    "# 定义多分类数据集 - train_dataloader - test_dataloader\n",
    "batch_size = 128\n",
    "# Build the training and testing dataset\n",
    "traindataset = torchvision.datasets.FashionMNIST(root='E:\\\\DataSet\\\\FashionMNIST\\\\Train',\n",
    "                                                  train=True,\n",
    "                                                  download=True,\n",
    "                                                  transform=transforms.ToTensor())\n",
    "testdataset = torchvision.datasets.FashionMNIST(root='E:\\\\DataSet\\\\FashionMNIST\\\\Test',\n",
    "                                                 train=False,\n",
    "                                                 download=True,\n",
    "                                                 transform=transforms.ToTensor())\n",
    "traindataloader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, shuffle=True)\n",
    "testdataloader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size, shuffle=False)\n",
    "# 绘制图像的代码\n",
    "def picture(name, trainl, testl, type='Loss'):\n",
    "    plt.rcParams[\"font.sans-serif\"]=[\"SimHei\"] #设置字体\n",
    "    plt.rcParams[\"axes.unicode_minus\"]=False #该语句解决图像中的“-”负号的乱码问题\n",
    "    plt.title(name) # 命名\n",
    "    plt.plot(trainl, c='g', label='Train '+ type)\n",
    "    plt.plot(testl, c='r', label='Test '+type)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "print(f'多分类数据集 样本总数量{len(traindataset) + len(testdataset)},训练样本数量{len(traindataset)},测试样本数量{len(testdataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59fe9b-7868-4a70-9af4-45dd8e62cd12",
   "metadata": {},
   "source": [
    "**1.手动实现前馈神经网络代码**  \n",
    "1. 代码中`MyNet`为手动实现的前馈神经网络模型，包含一个参数 dropout 表示丢失率用作实验一中设置不同的丢失率\n",
    "2. 代码设置函数`train_and_test`可供之后需要手动实现多分类的实验调用，默认的损失函数为 `CrossEntropyLoss()`,优化函数为自己定义的随机梯度下降函数`mySGD()`,其余参数设置如下：\n",
    "    + `epochs=40` 表示需要训练的总epoch数 默认为 40  \n",
    "    + `lr=0.01` 表示设置的学习率, 默认值为 0.01  \n",
    "    + `L2=False` 表示是否需要加入L2惩罚范数，默认值为False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c4b665-1c50-4a34-a557-36db17664b48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\System_Cache\\ipykernel_16408\\2970478061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m定义的优化函数\u001b[0m\u001b[0;31m，\u001b[0m\u001b[0m默认为自己定义的mySGD函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMyNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mtrain_all_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 记录训练集上得loss变化\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mtest_all_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 记录测试集上的loss变化\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\System_Cache\\ipykernel_16408\\2970478061.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dropout)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnum_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;31m# 十分类问题\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         w_1 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_inputs)), dtype=torch.float32,\n\u001b[0m\u001b[0;32m     11\u001b[0m                            requires_grad=True)\n\u001b[0;32m     12\u001b[0m         \u001b[0mb_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_hiddens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 定义自己的前馈神经网络\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "class MyNet():\n",
    "    def __init__(self,dropout=0):\n",
    "        # 设置隐藏层和输出层的节点数\n",
    "        self.dropout = dropout\n",
    "        self.is_train = None\n",
    "        num_inputs, num_hiddens, num_outputs = 28 * 28, 256, 10  # 十分类问题\n",
    "        w_1 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_inputs)), dtype=torch.float32,\n",
    "                           requires_grad=True)\n",
    "        b_1 = torch.zeros(num_hiddens, dtype=torch.float32, requires_grad=True)\n",
    "        w_2 = torch.tensor(np.random.normal(0, 0.01, (num_outputs, num_hiddens)), dtype=torch.float32,\n",
    "                           requires_grad=True)\n",
    "        b_2 = torch.zeros(num_outputs, dtype=torch.float32, requires_grad=True)\n",
    "        self.params = [w_1, b_1, w_2, b_2]\n",
    "        self.w = [w_1,w_2]\n",
    "        # 定义模型结构\n",
    "        self.input_layer = lambda x: x.view(x.shape[0], -1)\n",
    "        self.hidden_layer = lambda x: self.my_relu(torch.matmul(x, w_1.t()) + b_1)\n",
    "        self.output_layer = lambda x: torch.matmul(x, w_2.t()) + b_2\n",
    "    \n",
    "    def my_relu(self, x):\n",
    "        return torch.max(input=x, other=torch.tensor(0.0))\n",
    "    # 以下两个函数分别在训练和测试前调用，选择是否需要dropout\n",
    "    def train(self):\n",
    "        self.is_train = True\n",
    "    def test(self):\n",
    "        self.is_train = False\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        if self.is_train: # 如果是训练过程，则需要开启dropout 否则 需要关闭 dropout\n",
    "            x = dropout_layer(x,dropout=self.dropout) \n",
    "        x = self.my_relu(self.hidden_layer(x))\n",
    "        if self.is_train:\n",
    "            x = dropout_layer(x,dropout=self.dropout)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "定义dropout层\n",
    "x: 输入数据\n",
    "dropout: 随机丢弃的概率\n",
    "\"\"\"\n",
    "def dropout_layer(x, dropout):\n",
    "    assert 0 <= dropout <= 1 #dropout值必须在0-1之间\n",
    "    # dropout==1，所有元素都被丢弃。\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(x)\n",
    "        # 在本情况中，所有元素都被保留。\n",
    "    if dropout == 0:\n",
    "        return x\n",
    "    mask = (torch.rand(x.shape) > dropout).float() #rand()返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数\n",
    "    return mask * x / (1.0 - dropout)\n",
    "\n",
    "# 默认的优化函数为手写的mySGD\n",
    "def mySGD(params, lr, batchsize):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad\n",
    "\n",
    "# 定义L2范数惩罚项 参数 w 为模型的 w 在本次实验中为[w_1, w_2] batch_size=128\n",
    "def l2_penalty(w):\n",
    "    cost = 0\n",
    "    for i in range(len(w)):\n",
    "        cost += (w[i]**2).sum()\n",
    "    return cost / batch_size / 2\n",
    "\"\"\"\n",
    "定义训练函数\n",
    "model:定义的模型 默认为MyNet(0) 即无dropout的初始网络\n",
    "epochs:训练总轮数 默认为40\n",
    "criterion:定义的损失函数，默认为cross_entropy\n",
    "lr :学习率 默认为0.1\n",
    "optimizer:定义的优化函数，默认为自己定义的mySGD函数\n",
    "\"\"\"\n",
    "def train_and_test(model=MyNet(),epochs=40,lr=0.01,L2=False):\n",
    "    train_all_loss = []  # 记录训练集上得loss变化\n",
    "    test_all_loss = []  # 记录测试集上的loss变化\n",
    "    train_ACC, test_ACC = [], [] # 记录正确的个数\n",
    "    begintime = time.time()\n",
    "    optimizer=mySGD # 激活函数为自己定义的mySGD函数\n",
    "    # criterion = cross_entropy # 损失函数为交叉熵函数\n",
    "    criterion = CrossEntropyLoss() # 损失函数\n",
    "    model.train() #表明当前处于训练状态，允许使用dropout\n",
    "    for epoch in range(epochs):\n",
    "        train_l,train_acc_num = 0, 0\n",
    "        for data, labels in traindataloader:\n",
    "            pred = model.forward(data)\n",
    "            train_each_loss = criterion(pred, labels)  # 计算每次的损失值\n",
    "            # 若L2为True则表示需要添加L2范数惩罚项\n",
    "            if L2 == True:\n",
    "                train_each_loss += lambd * l2_penalty(model.w)\n",
    "            train_l += train_each_loss.item()\n",
    "            train_each_loss.backward()  # 反向传播\n",
    "            optimizer(model.params, lr, 128)  # 使用小批量随机梯度下降迭代模型参数\n",
    "            # 梯度清零\n",
    "            train_acc_num += (pred.argmax(dim=1)==labels).sum().item()\n",
    "            for param in model.params:\n",
    "                param.grad.data.zero_()\n",
    "            # print(train_each_loss)\n",
    "        train_all_loss.append(train_l)  # 添加损失值到列表中\n",
    "        train_ACC.append(train_acc_num / len(traindataset)) # 添加准确率到列表中\n",
    "        model.test() # 表明当前处于测试状态，无需使用dropout\n",
    "        with torch.no_grad():\n",
    "            is_train = False  # 表明当前为测试阶段，不需要dropout参与\n",
    "            test_l, test_acc_num = 0, 0\n",
    "            for data, labels in testdataloader:\n",
    "                pred = model.forward(data)\n",
    "                test_each_loss = criterion(pred, labels)\n",
    "                test_l += test_each_loss.item()\n",
    "                test_acc_num += (pred.argmax(dim=1)==labels).sum().item()\n",
    "            test_all_loss.append(test_l)\n",
    "            test_ACC.append(test_acc_num / len(testdataset))   # # 添加准确率到列表中\n",
    "        if epoch == 0 or (epoch + 1) % 4 == 0:\n",
    "            print('epoch: %d | train loss:%.5f | test loss:%.5f | train acc: %.2f | test acc: %.2f'\n",
    "                  % (epoch + 1, train_l, test_l, train_ACC[-1],test_ACC[-1]))\n",
    "    endtime = time.time()\n",
    "    print(\"手动实现dropout = 0.2 %d轮 总用时: %.3f\" % (epochs, endtime - begintime))\n",
    "    return train_all_loss,test_all_loss,train_ACC,test_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aac301-fe38-4140-a9db-1546079567e2",
   "metadata": {},
   "source": [
    "### 1.2.1 手动实现-设置dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b3f27-e503-4902-98b0-a344330384a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0  dropout = 0  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\n",
    "model_11 = MyNet(dropout=0)\n",
    "train_all_loss11,test_all_loss11,\\\n",
    "train_ACC11,test_ACC11 \\\n",
    "= train_and_test(model=model_11,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e681e5-2b89-4083-85a8-71249ae56686",
   "metadata": {},
   "source": [
    "### 1.2.2 手动实现-设置dropout = 0.3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c5db4-7faa-425f-b8aa-8fd5898aa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0.3  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\n",
    "model_12 = MyNet(dropout=0.3)\n",
    "train_all_loss12,test_all_loss12,\\\n",
    "train_ACC12,test_ACC12 \\\n",
    "= train_and_test(model=model_12,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fb582-89d6-44b4-846d-f5ae00671374",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2.3 手动实现-设置dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe88cda-744d-4de9-a3ef-e6b0c04d35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0.6  dropout = 0.6  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\n",
    "model_13 = MyNet(dropout=0.6)\n",
    "train_all_loss13,test_all_loss13,\\\n",
    "train_ACC13,test_ACC13 \\\n",
    "= train_and_test(model=model_13,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6f660-aa81-4457-b4d5-b9bd611c207f",
   "metadata": {},
   "source": [
    "### 1.2.4 手动实现-设置dropout = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe8766-4579-4d2e-a32c-b6d51749708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0.9  dropout = 0.9  epoch = 40  lr = 0.01  optimizer = mySGD\n",
    "\n",
    "model_14 = MyNet(dropout=0.9)\n",
    "train_all_loss14,test_all_loss14,\\\n",
    "train_ACC14,test_ACC14 \\\n",
    "= train_and_test(model=model_14,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81408e39-9baf-4727-a019-12f6bdf1c5e9",
   "metadata": {},
   "source": [
    "  \n",
    "**2.利用torch.nn实现前馈神经网络代码**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69bd74d0-fb06-4c9a-8078-55d803c2ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用torch.nn实现前馈神经网络-多分类任务\n",
    "from collections import OrderedDict\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "# 定义自己的前馈神经网络\n",
    "class MyNet_NN(nn.Module):\n",
    "    def __init__(self,dropout=0.0):\n",
    "        super(MyNet_NN, self).__init__()\n",
    "        # 设置隐藏层和输出层的节点数\n",
    "        self.num_inputs, self.num_hiddens, self.num_outputs = 28 * 28, 256, 10  # 十分类问题\n",
    "        # 定义模型结构\n",
    "        self.input_layer = nn.Flatten()\n",
    "        self.hidden_layer = nn.Linear(28*28,256)\n",
    "        # 根据设置的dropout设置丢失率\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(256,10)\n",
    "        # 使用relu激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.input_layer(x))\n",
    "        x = self.drop(self.hidden_layer(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# 训练\n",
    "# 使用默认的参数即： num_inputs=28*28,num_hiddens=256,num_outs=10,act='relu'\n",
    "model = MyNet_NN()  \n",
    "model = model.to(device)\n",
    "\n",
    "# 将训练过程定义为一个函数，方便调用\n",
    "def train_and_test_NN(model=model,epochs=40,lr=0.01):\n",
    "    MyModel = model\n",
    "    print(MyModel)\n",
    "    optimizer = SGD(MyModel.parameters(), lr=lr)  # 优化函数\n",
    "    criterion = CrossEntropyLoss() # 损失函数\n",
    "    train_all_loss = []  # 记录训练集上得loss变化\n",
    "    test_all_loss = []  # 记录测试集上的loss变化\n",
    "    train_ACC, test_ACC = [], []\n",
    "    begintime = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train_l, train_epoch_count, test_epoch_count = 0, 0, 0\n",
    "        for data, labels in traindataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            pred = MyModel(data)\n",
    "            train_each_loss = criterion(pred, labels.view(-1))  # 计算每次的损失值\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "            train_each_loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 梯度更新\n",
    "            train_l += train_each_loss.item()\n",
    "            train_epoch_count += (pred.argmax(dim=1)==labels).sum()\n",
    "        train_ACC.append(train_epoch_count.cpu()/len(traindataset))\n",
    "        train_all_loss.append(train_l)  # 添加损失值到列表中\n",
    "        with torch.no_grad():\n",
    "            test_loss, test_epoch_count= 0, 0\n",
    "            for data, labels in testdataloader:\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                pred = MyModel(data)\n",
    "                test_each_loss = criterion(pred,labels)\n",
    "                test_loss += test_each_loss.item()\n",
    "                test_epoch_count += (pred.argmax(dim=1)==labels).sum()\n",
    "            test_all_loss.append(test_loss)\n",
    "            test_ACC.append(test_epoch_count.cpu()/len(testdataset))\n",
    "        if epoch == 0 or (epoch + 1) % 4 == 0:\n",
    "            print('epoch: %d | train loss:%.5f | test loss:%.5f | train acc:%5f test acc:%.5f:' % (epoch + 1, train_all_loss[-1], test_all_loss[-1],\n",
    "                                                                                                                     train_ACC[-1],test_ACC[-1]))\n",
    "    endtime = time.time()\n",
    "    print(\"torch.nn实现前馈网络-多分类任务 %d轮 总用时: %.3fs\" % (epochs, endtime - begintime))\n",
    "    # 返回训练集和测试集上的 损失值 与 准确率\n",
    "    return train_all_loss,test_all_loss,train_ACC,test_ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbf009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.3.1 torch.nn实现-设置dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "135ac4d3-c521-4bca-bd64-d2945348c5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet_NN(\n",
      "  (input_layer): Flatten(start_dim=1, end_dim=-1)\n",
      "  (hidden_layer): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0, inplace=False)\n",
      "  (output_layer): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "epoch: 1 | train loss:659.22677 | test loss:74.46372 | train acc:0.620433 test acc:0.68020:\n",
      "epoch: 4 | train loss:292.03407 | test loss:48.62702 | train acc:0.792500 test acc:0.78780:\n",
      "epoch: 8 | train loss:239.93499 | test loss:41.59586 | train acc:0.827450 test acc:0.81610:\n",
      "epoch: 12 | train loss:220.08005 | test loss:38.91176 | train acc:0.839300 test acc:0.82600:\n",
      "epoch: 16 | train loss:208.55522 | test loss:37.24038 | train acc:0.846550 test acc:0.83370:\n",
      "epoch: 20 | train loss:200.48044 | test loss:35.91030 | train acc:0.851833 test acc:0.83970:\n",
      "epoch: 24 | train loss:193.93721 | test loss:35.25744 | train acc:0.857167 test acc:0.83970:\n",
      "epoch: 28 | train loss:188.91335 | test loss:34.40012 | train acc:0.861000 test acc:0.84520:\n",
      "epoch: 32 | train loss:184.05572 | test loss:33.65186 | train acc:0.864017 test acc:0.85060:\n",
      "epoch: 36 | train loss:179.96731 | test loss:33.72948 | train acc:0.868133 test acc:0.84780:\n",
      "epoch: 40 | train loss:176.11395 | test loss:32.47842 | train acc:0.869950 test acc:0.85550:\n",
      "torch.nn实现前馈网络-多分类任务 40轮 总用时: 343.192s\n"
     ]
    }
   ],
   "source": [
    "# 设置dropout = 0  dropout = 0  epoch = 40  lr = 0.01  optimizer = SGD\n",
    "\n",
    "model_15 = MyNet_NN(dropout=0)\n",
    "model_15 = model_15.to(device)\n",
    "train_all_loss15,test_all_loss15,train_ACC15,test_ACC15 = train_and_test_NN(model=model_15,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de93619-858e-48fd-858f-d88a41b5dfe8",
   "metadata": {},
   "source": [
    "### 1.3.2 torch.nn实现-设置dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a662cd-e384-4e1b-a8fa-1172b3f67f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0  dropout = 0  epoch = 40  lr = 0.01  optimizer = SGD\n",
    "model_16 = MyNet_NN(dropout=0.3)\n",
    "model_16 = model_16.to(device)\n",
    "train_all_loss16,test_all_loss16,train_ACC16,test_ACC16 = train_and_test_NN(model=model_16,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056aaf5-eb32-4e5b-9b4b-32f8aedc4148",
   "metadata": {},
   "source": [
    "### 1.3.3 torch.nn实现-设置dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36726ad-7cd1-4d6c-9f2a-85fd3b34a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0  dropout = 0  epoch = 40  lr = 0.01  optimizer = SGD\n",
    "model_17 = MyNet_NN(dropout=0.6)\n",
    "model_17 = model_17.to(device)\n",
    "train_all_loss17,test_all_loss17,train_ACC17,test_ACC17 = train_and_test_NN(model=model_17,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579196bb-62ca-44a9-a516-a6fd33bb0fdd",
   "metadata": {},
   "source": [
    "### 1.3.4 torch.nn实现-设置dropout = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fc5e2-7a54-484a-9a71-ac3bd4174a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置dropout = 0  dropout = 0  epoch = 40  lr = 0.01  optimizer = SGD\n",
    "model_18 = MyNet_NN(dropout=0)\n",
    "model_18 = model_18.to(device)\n",
    "train_all_loss18,test_all_loss18,train_ACC18,test_ACC18 = train_and_test_NN(model=model_18,epochs=40,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59f6b142-9994-4b2d-be81-565a8ec425e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.6158)\n",
      "tensor(7.6158)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def l2_penalty(w):\n",
    "    return torch.sqrt((w**2).sum())\n",
    "a = torch.tensor([2,2,3,4,5],dtype=torch.float32)\n",
    "print(l2_penalty(a))\n",
    "print(torch.norm(a,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e5a73-92d7-4390-aa6a-7ae11d495dd9",
   "metadata": {},
   "source": [
    "## 1.4实验结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66b532-d13d-4d58-b191-f38d20316d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaca0561",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ca263-02d2-446a-a487-46070e125e58",
   "metadata": {},
   "source": [
    "# 二、在多分类任务中分别手动实现和用torch.nn实现$L_2$正则化\n",
    "\n",
    "## 2.1 任务内容\n",
    "\n",
    "1. 任务具体要求  \n",
    "在多分类任务中分别手动实现和用torch.nn实现$L_2$正则化  \n",
    "2. 任务目的  \n",
    "探究惩罚项的权重对实验结果的影响（可用loss曲线进行展示）\n",
    "3. 任务算法或原理介绍    \n",
    "$L_2$ 原理   \n",
    "\n",
    "4. 任务所用数据集   \n",
    "   MNIST手写体数据集:  \n",
    "     + 该数据集包含60,000个用于训练的图像样本和10,000个用于测试的图像样本。  \n",
    "     + 图像是固定大小(28x28像素)，其值为0到1。为每个图像都被平展并转换为784  \n",
    "        \n",
    "## 2.2 任务思路及代码  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5e7c2-1a1e-45e7-8b06-31f5d0b51691",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.1 手动实现-设置惩罚权重lambd= 0(即无惩罚权重)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45e8f1-4d0b-420c-adc0-792ca85be1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "847b273f-2550-4aa0-8cab-fbec255294fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.2 手动实现-设置惩罚权重lambd= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb65e5e-0002-4bee-98c9-a5eb1bc9e627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1200b9b-da27-46e7-a8c7-474afb88a855",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2.3 手动实现-设置惩罚权重lambd= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bf701-3e1b-4b7b-bd36-531413f075e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02fa0e2b-3d98-4231-a9dd-a62642254403",
   "metadata": {},
   "source": [
    "### 2.3.1 利用torch.nn实现-设置惩罚权重lambd= 0(即无惩罚权重)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e52d97-1fb8-4fc4-83ea-3a97e02abe22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4d6b3e-9886-47d1-a728-138e55eb6ca3",
   "metadata": {},
   "source": [
    "### 2.3.2利用torch.nn实现-设置惩罚权重lambd= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646198c-8686-4bfa-92b4-1b8a416f2460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750ddad6-2cd6-488c-970d-dc1914b0e544",
   "metadata": {},
   "source": [
    "### 2.3.3 利用torch.nn实现-设置惩罚权重lambd= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a06f9-63ed-41e0-bc8d-932084445451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcb12a45-a334-4aa1-8de2-10d403fe1552",
   "metadata": {},
   "source": [
    "## 2.4 实验结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d95400-6110-4ad5-ac70-25b142f7610c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89749034-cea6-4dbb-8e46-9e276d5a5181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f0e8a-4528-4f14-a2c9-cb697a8ca578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886c11f-df99-498a-8e6e-768e0156e2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "121f592e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabe468",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# A1 实验心得\n",
    "\n",
    "学会手动构建前馈神经网络和利用torch.nn构建前馈神经网络解决回归、二分类、和多分类问题\n",
    "1. 实验中发现学习率的设置至关重要，如果学习率过大则会导致准确率下降的趋势，若学习率过小会导致模型需要更多时间收敛\n",
    "2. 实验过程中发现出现过拟合现象，通过修改相关参数得以纠正\n",
    "3. 学会程序模块话的编写，避免重复编写代码\n",
    "4. 对激活函数的选取有了更加清晰的认识\n",
    "5. 隐藏层的个数和隐藏层的神经元个数对模型有着很大的影响。\n",
    "\n",
    "# A2 参考文献  \n",
    "参考课程PPT"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
